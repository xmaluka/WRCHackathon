{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6z7ncXirnv7"
   },
   "source": [
    "# Building an ETL Pipeline for WRC Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jtYowqI_RiBL"
   },
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "\n",
    "import tweepy as tw         \n",
    "import pandas as pd     \n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "import json\n",
    "import re\n",
    "from IPython.display import display\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lquylmvOnFvt"
   },
   "outputs": [],
   "source": [
    "# API Keys\n",
    "\n",
    "CONSUMER_KEY    = '9qH6416zLY2GENYQzvkeFyP2o'\n",
    "CONSUMER_SECRET = '8XOo0ENIQy4HjX5jXC1xSdfj7jiOqubesglT29QsKkmHaDtEeh'\n",
    "\n",
    "ACCESS_TOKEN  = '1219722321289777164-hlhI8xizj3M39DU6VdVhsPyQuAWbgF'\n",
    "ACCESS_SECRET = 'l2WyzCqaaUfadV9P4N53zjJ3OOvqUb0IxNskk2GyOAiMM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create authentication\n",
    "\n",
    "auth = tw.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both sets need expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " key_words = [ 'leak' , 'burst' , 'pressure', 'water','cut', 'pipe',\n",
    "              'fault', 'broke', 'damage', 'toilet', 'sanit',\n",
    "              'waste', 'complain', 'supply','service','deliver',\n",
    "              'out', 'no', 'reference','report' ,'complain',\n",
    "              'install','low','repair']\n",
    "#Words like flow included in 'low','broken' in 'broke' (Pseudo lemmatization)\n",
    "#Includes word like follow..\n",
    "#Still to consider outage vs out --using out for now\n",
    "#sanitation vs sanit (sanitory...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_list =[['alfred_enzo' ,'@alfrednzoDM', 'eastern_cape'],\n",
    "#               ['amajuba' ,'@AmajubaDM' , 'kwazulu_natal' ],\n",
    "#               ['cape_wine_lands','@CWDM2','western_cape'],\n",
    "#               ['ehlanzeni' ,'@EhlanzeniM','mpumalanga'],\n",
    "#               ['fezile_dabi', '@FezileDabiDM','free_state' ],\n",
    "#               ['garden_route', '@GardenRoute_DM','western_cape'],\n",
    "#               ['gert_sibande','@GertSibandeDM','mpumalanga' ],\n",
    "#               ['ilembe' ,'@DistrictIlembe','kwazulu_natal'],\n",
    "#               ['king_cetshwayo','@Cetshwayo_dm','kwazulu_natal'],\n",
    "#               ['lejweleputswa', '@LejweleputswaM','free_state' ],\n",
    "#               ['mangaung', '@MangaungCity','free_state' ],\n",
    "#               ['nkangala', '@NkangalaDM','mpumalanga' ],\n",
    "#               ['sedibeng', '@SedibengDM','gauteng' ],\n",
    "#               ['ugu', '@UguDM','kwazulu_natal'],\n",
    "#               ['north_uthungulu','@UmkhanyakudeM','kwazulu_natal'],\n",
    "#               ['uthukela', '@OkhahlambaLM','kwazulu_natal'],\n",
    "#               ['vhembe', '@VhembeDM','limpopo'],\n",
    "#               ['rand_west_city', '@RandLocal','gauteng' ],\n",
    "#               ['sedibeng' ,'@EmfuleniLM','gauteng' ],\n",
    "#               ['amathole','@Amathole_DM', 'eastern_cape'] , \n",
    "#               [ 'bojanala','Bojanala District', 'north_west'], \n",
    "#               [ 'capricon' ,'@CDMunicipality 'limpopo'], \n",
    "#               ['karoo' ,'Central Karoo District', 'western_cape'],\n",
    "#               ['chris_hani' ,'@ChrisHaniDM', 'eastern_cape'], \n",
    "#               ['kenneth_kaunda','Dr Kenneth Kaunda District', 'north_west'], \n",
    "#               ['dr_ruth','Dr Ruth Segomotsi Mompati District', 'north_west'] ,\n",
    "#               ['frances','@FrancesBaardDM', 'northern_cape'],\n",
    "#               ['harry_gwala','Harry Gwala District', 'kwazulu_natal'], \n",
    "#               ['joe_gqabi','Joe Gqabi District', 'eastern_cape' ],\n",
    "#               ['john_taolo','@JTGMunicipal', 'northern_cape'], \n",
    "#               ['mopani','Mopani District', 'limpopo'],\n",
    "#               ['namakwa','Namakwa District', 'northern_Cape'], \n",
    "#               ['ngaka','Ngaka Modiri Molema', 'north_west'], \n",
    "#               ['or_tambo' ,'@ortambodm', 'eastern_cape'], \n",
    "#               ['overberge','Overberg District', 'western_cape'],\n",
    "#               ['pixley_ka_seme','Pixley ka Seme District', 'northern_cape'], \n",
    "#               ['sarah', 'Sarah Baartman District', 'eastern_cape'],\n",
    "#               ['sekhukune','@SEKHUKHUNEMUNI1', 'limpopo'],\n",
    "#               ['thabo','@TeamTMDM', 'free_state'] ,\n",
    "#               ['umgungundlovu' ,'uMgungundlovu District', 'kwazulu_natal'] ,\n",
    "#               ['umzinyathi','@umzinyathi', 'kwazulu_natal'],\n",
    "#               ['waterberg','Waterberg District', 'limpopo' ],\n",
    "#               ['west_cost' ,'@WeskusDM', 'western_cape'], \n",
    "#               ['zf_mchunu' ,'ZF Mgcawu District', 'northern_cape'],\n",
    "#               ['xhariep' ,'Xhariep District', 'free_state'],\n",
    "#               ['zululand' ,'Zululand District', 'kwazulu_natal']]\n",
    "master_list = [['','@thameswater','']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets(search_word) :\n",
    "\n",
    "    search_words = search_word + \" -filter:retweets\"\n",
    "    today = date.today()                     \n",
    "    tweets = tw.Cursor(api.search,\n",
    "               q=search_words,\n",
    "               lang=\"en\"\n",
    "               ).items(200)                    \n",
    "    tweet_status = [tweet for tweet in tweets]\n",
    "    tweet_list = [tweet.text for tweet in tweet_status]\n",
    "    tweet_date = [tweet.created_at for tweet in tweet_status]\n",
    "    location_1 = [tweet.user.location for tweet in tweet_status]\n",
    "#     co_od = [tweet.coordinates for tweet in tweet_status]\n",
    "    place_name = [tweet.place.full_name if tweet.place else 'Not available' for tweet in tweet_status]\n",
    "\n",
    "    tweet_df = pd.DataFrame(data=tweet_list, \n",
    "        columns=['tweet'])\n",
    "    tweet_df['timestamp'] = tweet_date\n",
    "#     tweet_df['coordinates'] = co_od\n",
    "    tweet_df['Place_name'] = place_name\n",
    "    tweet_df['loc_1'] = location_1\n",
    "        \n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TweetCleaner(tweet):\n",
    "    tweet = str(tweet.lower()) \n",
    "    tweet = re.sub('@[\\w]*','',tweet) \n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "#     tweet = re.sub(r'#\\w*', '', tweet) might put issue in hashtag\n",
    "    tweet = re.sub(r\"[,.;':@#?!\\&/$]+\\ *\", ' ', tweet)\n",
    "    tweet = re.sub(r\"U+FFFD \", ' ', tweet)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    tweet = tweet.lstrip(' ')\n",
    "    tweet = ' '.join([i for i in tweet.split() if any(list_word in i for list_word in key_words)])  \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(the_list) :\n",
    "    col_order = ['tweet', 'timestamp','keywords' ,'Place_name','loc_1']   \n",
    "    dummy_df = pd.DataFrame(columns = ['tweet', 'timestamp','keywords' ,'Place_name','loc_1'])\n",
    "\n",
    "    for i in the_list :\n",
    "        handle = i[1]\n",
    "        df = extract_tweets(handle)\n",
    "        df['keywords'] = df['tweet'].map(lambda x: TweetCleaner(x))\n",
    "        df = df[col_order]\n",
    "\n",
    "        dummy_df = dummy_df.append(df)\n",
    "    \n",
    "    dummy_df = dummy_df.drop([0])\n",
    "    dummy_df = dummy_df.reset_index()\n",
    "    dummy_df = dummy_df.drop(columns = ['index'] , axis = 1)   \n",
    "    \n",
    "    return dummy_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_new = create_df(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Place_name</th>\n",
       "      <th>loc_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thameswater We will have a look when we can ,...</td>\n",
       "      <td>2020-08-06 12:52:42</td>\n",
       "      <td></td>\n",
       "      <td>Not available</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@thameswater Hi Daisy it is the broadway Winch...</td>\n",
       "      <td>2020-08-06 12:49:47</td>\n",
       "      <td>now</td>\n",
       "      <td>Not available</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@thameswater Thanks but eventually got through</td>\n",
       "      <td>2020-08-06 12:49:37</td>\n",
       "      <td></td>\n",
       "      <td>Not available</td>\n",
       "      <td>Richmond, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Another new @LifeatBromford Sewerage Treatment...</td>\n",
       "      <td>2020-08-06 12:47:13</td>\n",
       "      <td>another delivery</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Cirencester UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@thameswater there are still leaks in Red Lion...</td>\n",
       "      <td>2020-08-06 12:29:32</td>\n",
       "      <td>leaks</td>\n",
       "      <td>Not available</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>@thameswater hi there, I still haven’t been cr...</td>\n",
       "      <td>2020-08-04 15:01:25</td>\n",
       "      <td></td>\n",
       "      <td>Not available</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>@thameswater So newham council don’t want to h...</td>\n",
       "      <td>2020-08-04 14:59:31</td>\n",
       "      <td>no</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Plaistow london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>@thameswater I’ve constantly got onto the coun...</td>\n",
       "      <td>2020-08-04 14:56:13</td>\n",
       "      <td>water know</td>\n",
       "      <td>Not available</td>\n",
       "      <td>Plaistow london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>@thameswater it is dangerous on Starts Hill. I...</td>\n",
       "      <td>2020-08-04 14:52:16</td>\n",
       "      <td>no</td>\n",
       "      <td>Not available</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>@thameswater Oh my god......nothing left to sa...</td>\n",
       "      <td>2020-08-04 14:30:28</td>\n",
       "      <td>nothing</td>\n",
       "      <td>Not available</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet           timestamp  \\\n",
       "0    @thameswater We will have a look when we can ,... 2020-08-06 12:52:42   \n",
       "1    @thameswater Hi Daisy it is the broadway Winch... 2020-08-06 12:49:47   \n",
       "2       @thameswater Thanks but eventually got through 2020-08-06 12:49:37   \n",
       "3    Another new @LifeatBromford Sewerage Treatment... 2020-08-06 12:47:13   \n",
       "4    @thameswater there are still leaks in Red Lion... 2020-08-06 12:29:32   \n",
       "..                                                 ...                 ...   \n",
       "194  @thameswater hi there, I still haven’t been cr... 2020-08-04 15:01:25   \n",
       "195  @thameswater So newham council don’t want to h... 2020-08-04 14:59:31   \n",
       "196  @thameswater I’ve constantly got onto the coun... 2020-08-04 14:56:13   \n",
       "197  @thameswater it is dangerous on Starts Hill. I... 2020-08-04 14:52:16   \n",
       "198  @thameswater Oh my god......nothing left to sa... 2020-08-04 14:30:28   \n",
       "\n",
       "             keywords     Place_name             loc_1  \n",
       "0                      Not available                    \n",
       "1                 now  Not available                    \n",
       "2                      Not available  Richmond, London  \n",
       "3    another delivery  Not available    Cirencester UK  \n",
       "4               leaks  Not available                    \n",
       "..                ...            ...               ...  \n",
       "194                    Not available   London, England  \n",
       "195                no  Not available  Plaistow london   \n",
       "196        water know  Not available  Plaistow london   \n",
       "197                no  Not available                    \n",
       "198           nothing  Not available                    \n",
       "\n",
       "[199 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'Bourton-on-the-Water, England'),\n",
       " (33, 'South East, England'),\n",
       " (34, 'St. Mary Magdalene, Boveney'),\n",
       " (81, 'Basingstoke, England'),\n",
       " (83, 'Tottenham, London'),\n",
       " (91, 'Cheltenham, England'),\n",
       " (92, 'Cheltenham, England'),\n",
       " (114, 'Enfield, London'),\n",
       " (135, 'Islington, London'),\n",
       " (150, 'Tottenham, London'),\n",
       " (165, 'Slough, South East'),\n",
       " (171, 'The Mousetrap Inn')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,v) for i,v in enumerate(database_new.Place_name) if v != 'Not available']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Richmond, London'),\n",
       " (3, 'Cirencester UK'),\n",
       " (5, 'Bourton on the water'),\n",
       " (6, 'Chislehurst, Kent'),\n",
       " (7, 'London, England'),\n",
       " (11, 'Harpenden, Herts '),\n",
       " (12, 'Wandsworth, London'),\n",
       " (13, '#digitalnomad'),\n",
       " (15, 'Liverpool - Sheffield'),\n",
       " (16, 'Chislehurst'),\n",
       " (17, 'Wiltshire, UK'),\n",
       " (18, 'Wiltshire, UK'),\n",
       " (19, 'Wiltshire, UK'),\n",
       " (20, 'Station Road, RWB'),\n",
       " (22, 'Wiltshire, UK'),\n",
       " (23, 'Here'),\n",
       " (24, 'London'),\n",
       " (25, 'Here'),\n",
       " (27, 'London'),\n",
       " (28, 'England'),\n",
       " (29, 'UK, Australia, the Philippines'),\n",
       " (30, 'London, England'),\n",
       " (31, 'London'),\n",
       " (32, 'Helping food brands get sales'),\n",
       " (33, 'Windsor, Berkshire'),\n",
       " (34, 'Windsor, Berkshire'),\n",
       " (36, 'Hackney London N16'),\n",
       " (42, 'london, uk'),\n",
       " (44, 'London, UK'),\n",
       " (45, 'Gloucestershire'),\n",
       " (46, 'Richmond, London'),\n",
       " (47, '#digitalnomad'),\n",
       " (48, 'Liverpool - Sheffield'),\n",
       " (49, 'Wiltshire, UK'),\n",
       " (50, 'Liverpool - Sheffield'),\n",
       " (51, 'Wiltshire, UK'),\n",
       " (52, 'Liverpool - Sheffield'),\n",
       " (53, 'Wiltshire, UK'),\n",
       " (54, 'London'),\n",
       " (55, 'Oxfordshire'),\n",
       " (56, 'LWT Website:'),\n",
       " (57, 'Guildford, Surrey'),\n",
       " (58, 'Aylesbury, United Kingdom'),\n",
       " (59, 'London'),\n",
       " (60, 'London, England'),\n",
       " (61, 'South East, England'),\n",
       " (62, 'Hackney London N16'),\n",
       " (63, 'Hackney London N16'),\n",
       " (64, 'Bexley, London'),\n",
       " (65, 'Chislehurst'),\n",
       " (66, 'London'),\n",
       " (70, 'London'),\n",
       " (71, 'London'),\n",
       " (72, 'London'),\n",
       " (73, 'Hackney London N16'),\n",
       " (75, 'London'),\n",
       " (76, 'Surrey'),\n",
       " (77, 'Hackney London N16'),\n",
       " (78, 'London'),\n",
       " (79, 'London'),\n",
       " (80, 'South East, England'),\n",
       " (81, 'Basingstoke, England'),\n",
       " (84, 'Oxford, actually'),\n",
       " (85, 'Torfaen, Wales'),\n",
       " (88, 'Sheffield'),\n",
       " (90, 'London, England'),\n",
       " (91, 'Bourton on the water'),\n",
       " (92, 'Bourton on the water'),\n",
       " (93, 'London'),\n",
       " (95, 'Camberwell'),\n",
       " (96, 'Camberwell'),\n",
       " (100, 'London'),\n",
       " (101, 'South East, England'),\n",
       " (102, 'Kingston upon Thames, London'),\n",
       " (103, 'she/her '),\n",
       " (105, 'London'),\n",
       " (107, 'The trough of disillusionment'),\n",
       " (109, 'Hackney'),\n",
       " (111, 'Aylesbury, England'),\n",
       " (112, 'London'),\n",
       " (115, 'Marlow, South East'),\n",
       " (116, 'London, England'),\n",
       " (117, 'Sunderland UK'),\n",
       " (118, 'Hackney, London'),\n",
       " (119, 'Oxford, UK'),\n",
       " (122, 'Near Oxford'),\n",
       " (123, 'United Kingdom'),\n",
       " (124, 'London, England'),\n",
       " (125, 'London'),\n",
       " (127, 'Here'),\n",
       " (128, 'UK'),\n",
       " (130, 'UK'),\n",
       " (131, 'she/her '),\n",
       " (133, 'Chipping Norton, England'),\n",
       " (135, 'N London'),\n",
       " (136, 'Preston, Lancashire'),\n",
       " (137, 'london'),\n",
       " (138, 'Gloucestershire'),\n",
       " (139, 'London'),\n",
       " (140, 'The Red North'),\n",
       " (142, 'Aylesbury, England'),\n",
       " (148, 'London'),\n",
       " (149, 'Cotswolds'),\n",
       " (151, 'London'),\n",
       " (154, 'Guildford, Surrey'),\n",
       " (155, 'Twitter: Mon-Fri 06:30-18:30'),\n",
       " (156, 'London'),\n",
       " (157, 'Rural Buckinghamshire UK.'),\n",
       " (158, 'London'),\n",
       " (159, 'UK'),\n",
       " (160, 'Guildford/Oxford/London'),\n",
       " (164, 'Woodley, England'),\n",
       " (165, 'SL3'),\n",
       " (166, 'London, England'),\n",
       " (167, 'oxford/chile lol'),\n",
       " (170, 'The Red North'),\n",
       " (171, 'Bourton on the water'),\n",
       " (172, 'Chigwell '),\n",
       " (173, 'Merton, London'),\n",
       " (174, 'Nottingham'),\n",
       " (176, 'Merton, London'),\n",
       " (178, 'London, England'),\n",
       " (179, 'Wiltshire'),\n",
       " (182, 'kent'),\n",
       " (183, 'London, England'),\n",
       " (186, 'London'),\n",
       " (188, 'Oxford/Reading/Coventry/Rugby'),\n",
       " (189, 'Pamplona ➡️ Oxford'),\n",
       " (190, 'Kent'),\n",
       " (191, 'Marlow, South East'),\n",
       " (193, 'West London'),\n",
       " (194, 'London, England'),\n",
       " (195, 'Plaistow london '),\n",
       " (196, 'Plaistow london ')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,v) for i,v in enumerate(database_new.loc_1) if v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_student_version.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
